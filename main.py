from diffusers import StableDiffusionPipeline,UniPCMultistepScheduler
import torch
import gc
import matplotlib.pyplot as plt
import gradio as gr
import random
import os
from openai import OpenAI
from google.colab import userdata
# å®šç¾©å¯ç”¨çš„æ¨¡å‹æ¸…å–®
models = {
    "MajicMIX Realistic v6": "digiplay/majicMIX_realistic_v6",
    "Realistic Vision V5.1": "SG161222/Realistic_Vision_V5.1_noVAE",
    "stable-diffusion-v1-5": "runwayml/stable-diffusion-v1-5",
}
model_name = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    use_safetensors=True
).to("cuda")
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
# åŠ è¼‰ä¸åŒæ¨¡å‹çš„å‡½æ•¸
def load_model(model_key):
    global pipe, model_name

    # ç²å–é¸æ“‡çš„æ¨¡å‹è·¯å¾‘
    model_name = models[model_key]


    # åŠ è¼‰æ–°æ¨¡å‹
    pipe = StableDiffusionPipeline.from_pretrained(
        model_name,
        torch_dtype=torch.float16,
        use_safetensors=True
    ).to("cuda")
    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)

    return f"å·²æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_key}"
# Groqç¿»è­¯æ©Ÿå™¨äºº
api_key = userdata.get('Groq')
os.environ['OPENAI_API_KEY'] = api_key

client = OpenAI(
    base_url = "https://api.groq.com/openai/v1"
)

def translate_to_english(text):
    """å°‡ä»»ä½•èªè¨€ç¿»è­¯æˆè‹±æ–‡"""
    # å¦‚æœæ–‡æœ¬ç‚ºç©ºï¼Œç›´æ¥è¿”å›
    if not text or text.strip() == "":
        return text

    # æª¢æŸ¥æ˜¯å¦æ˜¯è‹±æ–‡
    if all('\u4e00' > char or char > '\u9fff' for char in text):
        return text

    try:
        # å‰µå»ºç¿»è­¯è«‹æ±‚
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç¿»è­¯å°ˆå®¶ã€‚è«‹å°‡ç”¨æˆ¶è¼¸å…¥çš„ä»»ä½•èªè¨€ç¿»è­¯æˆè‹±æ–‡ï¼Œåªè¿”å›ç¿»è­¯çµæœã€‚"},
                {"role": "user", "content": f"å°‡ä»¥ä¸‹æ–‡æœ¬ç¿»è­¯æˆè‹±æ–‡: {text}"}
            ],
            temperature=0.1
        )

        # ç²å–ç¿»è­¯çµæœ
        translation = response.choices[0].message.content
        print(f"å·²ç¿»è­¯: {text} -> {translation}")
        return translation

    except Exception as e:
        print(f"ç¿»è­¯éŒ¯èª¤: {str(e)}")
        return text

# æ•´åˆç¿»è­¯åŠŸèƒ½çš„åœ–åƒç”Ÿæˆå‡½æ•¸
def generate_images(prompt, use_enhance, enhance_text, use_negative, negative_text,
                   use_custom_seed, custom_seed, height, width, steps, num_images):

    # ç¿»è­¯ä¸»è¦æç¤ºè©
    translated_prompt = translate_to_english(prompt)

    # ç¿»è­¯å¢å¼·æç¤ºè©
    translated_enhance_text = enhance_text
    if use_enhance and enhance_text:
        translated_enhance_text = translate_to_english(enhance_text)

    # ç¿»è­¯è² é¢æç¤ºè©
    translated_negative_text = negative_text
    if use_negative and negative_text:
        translated_negative_text = translate_to_english(negative_text)


    height = int(height)
    width = int(width)

    if height % 8 != 0 or width % 8 != 0:
        raise ValueError("é«˜åº¦å’Œå¯¬åº¦å¿…é ˆæ˜¯8çš„å€æ•¸ï¼")

    if use_custom_seed:
        base_seed = int(custom_seed)
    else:
        base_seed = random.randint(0, 2**32 - 1)

    seeds = [base_seed + i for i in range(num_images)]

    prompts = []
    negative_prompts = []
    generators = []

    # ä½¿ç”¨ç¿»è­¯å¾Œçš„æç¤ºè©
    final_prompt = translated_prompt
    if use_enhance and translated_enhance_text:
        final_prompt = translated_prompt + ", " + translated_enhance_text

    # ä½¿ç”¨ç¿»è­¯å¾Œçš„è² é¢æç¤ºè©
    final_negative = translated_negative_text if use_negative else None

    for seed in seeds:
        g = torch.Generator("cuda").manual_seed(seed)
        generators.append(g)
        prompts.append(final_prompt)
        negative_prompts.append(final_negative)

    gc.collect()
    torch.cuda.empty_cache()

    images = []
    for i in range(num_images):
        with torch.no_grad():
            image = pipe(
                prompt=prompts[i],
                negative_prompt=negative_prompts[i] if final_negative else None,
                height=height,
                width=width,
                num_inference_steps=steps,
                guidance_scale=7.5,
                generator=generators[i]
            ).images[0]
            images.append(image)

    return images, f"ä½¿ç”¨çš„ random seeds: {seeds}"

default_enhance = "detailed fur texture, bright eyes, whiskers, cinematic lighting"
default_negative = "human, person, ugly, blurry, distorted, deformed, low quality, bad anatomy"

with gr.Blocks(css=".gradio-container {background-color: #FAFAFA; padding: 20px;} .gr-button {font-size: 18px; background: linear-gradient(to right, #667eea, #764ba2); color: white;}") as demo:
    gr.Markdown("""
    # ğŸ¨ å¤šé¢¨æ ¼ AI åœ–åƒå·¥ä½œå®¤
    æ­¡è¿ä½¿ç”¨æ™ºèƒ½åœ–åƒç”Ÿæˆå™¨ï¼

    é¸æ“‡ä½ å–œæ„›çš„æ¨¡å‹ï¼Œè¼¸å…¥å‰µæ„æç¤ºè©ï¼Œèª¿æ•´ç´°ç¯€åƒæ•¸ï¼Œä¸€éµç”Ÿæˆä»¤äººé©šè±”çš„è—è¡“ä½œå“ã€‚ç„¡è«–æ˜¯å¯«å¯¦é¢¨æ ¼çš„ç²¾ç·»è‚–åƒã€å‹•æ¼«é¢¨æ ¼çš„è§’è‰²è¨­è¨ˆã€å¥‡å¹»å ´æ™¯é‚„æ˜¯è‡ªç„¶é¢¨å…‰ï¼Œéƒ½èƒ½è¼•é¬†å¯¦ç¾ã€‚èª¿æ•´åƒæ•¸æ¢ç´¢ç„¡é™å¯èƒ½ï¼Œè®“ä½ çš„å‰µæ„ç«‹å³æˆçœŸï¼

    æ¨¡å‹æä¾›ï¼š

    MajicMIX Realistic v6 æä¾›å„ªè³ªå¯«å¯¦é¢¨æ ¼èˆ‡ç´°è†©äººç‰©ç´°ç¯€ã€‚

    Realistic Vision V5.1 å°ˆæ³¨æ–¼æ¥µè‡´å¯«å¯¦èˆ‡å‡ºè‰²çš„å…‰å½±æè³ªè¡¨ç¾ã€‚

    Stable Diffusion v1.5 æ˜¯æœ€ç©©å®šä¸”å¤šåŠŸèƒ½çš„åŸºç¤æ¨¡å‹ï¼Œé©åˆå„ç¨®é¢¨æ ¼å‰µä½œã€‚

    """)

    # æ·»åŠ æ¨¡å‹é¸æ“‡ä¸‹æ‹‰é¸å–®
    model_dropdown = gr.Dropdown(
        choices=list(models.keys()),
        value="stable-diffusion-v1-5",
        label="é¸æ“‡æ¨¡å‹",
    )

    with gr.Row():
        with gr.Column(scale=6):
            prompt = gr.Textbox(label="Prompt", placeholder="è«‹è¼¸å…¥ä½ çš„æç¤ºè© (prompt)", lines=3)
            with gr.Row():
                use_enhance = gr.Checkbox(label="åŠ å¼· Prompt", value=True)
                enhance_text = gr.Textbox(label="åŠ å¼·å…§å®¹", value=default_enhance)
            with gr.Row():
                use_negative = gr.Checkbox(label="ä½¿ç”¨ Negative Prompt", value=True)
                negative_text = gr.Textbox(label="Negative Prompt å…§å®¹", value=default_negative)
            with gr.Row():
                use_custom_seed = gr.Checkbox(label="è‡ªè¨‚ Random Seed", value=False)
                custom_seed = gr.Number(label="æŒ‡å®š seed (é¸å¡«)", value=42)
            with gr.Row():
                height = gr.Dropdown(["512", "768", "1024"], label="é«˜åº¦ Height", value="512")
                width = gr.Dropdown(["512", "768", "1024"], label="å¯¬åº¦ Width", value="512")
            with gr.Row():
                steps = gr.Slider(10, 50, value=20, step=5, label="ç”Ÿæˆæ­¥æ•¸ (Steps)")
                num_images = gr.Slider(1, 4, step=1, value=1, label="ç”Ÿæˆå¼µæ•¸")
            generate_btn = gr.Button("ğŸš€ é–‹å§‹ç”Ÿæˆï¼")

        with gr.Column(scale=6):
            gallery = gr.Gallery(label="ç”Ÿæˆçµæœ", columns=2, object_fit="contain", height="auto")
            seed_info = gr.Label(label="ä½¿ç”¨çš„ Random Seeds")
            model_info = gr.Textbox(label="æ¨¡å‹è³‡è¨Š", value="å·²è¼‰å…¥æ¨¡å‹: stable-diffusion-v1-5")

    # æ¨¡å‹åˆ‡æ›äº‹ä»¶
    model_dropdown.change(
        fn=load_model,
        inputs=[model_dropdown],
        outputs=[model_info]
    )

    generate_btn.click(
        fn=generate_images,
        inputs=[prompt, use_enhance, enhance_text, use_negative, negative_text,
                use_custom_seed, custom_seed, height, width, steps, num_images],
        outputs=[gallery, seed_info]
    )

demo.launch(share=True, debug=True)
